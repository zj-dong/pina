<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="PINA: Learning a Personalized Implicit Neural Avatar from a Single RGB-D Video Sequence">
  <meta name="keywords" content="PINA">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>PINA: Learning a Personalized Implicit Neural Avatar from a Single RGB-D Video Sequence</title>


  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">PINA: Learning a Personalized Implicit Neural Avatar from a Single RGB-D Video Sequence</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://ait.ethz.ch/people/zijian/">Zijian Dong*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ait.ethz.ch/people/chen/">Chen Guo*</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ait.ethz.ch/people/song/">Jie Song</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://ait.ethz.ch/people/xu/">Xu Chen</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="http://www.cvlibs.net/">Andreas Geiger</a><sup>2,3</sup>,
            </span>
            <span class="author-block">
              <a href="https://ait.ethz.ch/people/hilliges/">Otmar Hilliges</a><sup>1</sup>
            </span>
          </div>

          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>ETH Zürich,</span>
            <span class="author-block"><sup>2</sup>University of Tübingen,</span>
            <br>
            <span class="author-block"><sup>3</sup>Max Planck Institute for Intelligent Systems, Tübingen
            </span>
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://ait.ethz.ch/projects/2022/pina/downloads/main.pdf"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Video Link. -->
              <span class="link-block">
                <a href="https://youtu.be/oGpKUuD54Qk"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-youtube"></i>
                  </span>
                  <span>Video</span>
                </a>
              </span>
              <!-- Medium Link. -->
              <!-- <span class="link-block">
                <a href="https://eth-ait.medium.com/animate-implicit-shapes-with-forward-skinning-c7ebbf355694"
                    class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-medium-m"></i>
                  </span>
                  <span>Medium</span>
                </a>
              </span> -->
              <!-- Blog Link. -->
              <!-- <span class="link-block">
                <a href="https://autonomousvision.github.io/snarf/"
                    class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-blogger-b"></i>
                  </span>
                  <span>Blog</span>
                </a>
              </span> -->
              <!-- Code Link. -->
              <span class="link-block">
                <a href="https://github.com/zj-dong/pina"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code (coming soon)</span>
                  </a>
              </span>
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
        <img src="https://ait.ethz.ch/projects/2022/pina/downloads/assets/teaser.png"  class="center"/>
      <h2 class="subtitle has-text-centered">
      
We propose PINA, a method to acquire personalized and animatable neural avatars from RGB-D videos. 
      
      </h2>
    </div>
  </div>
</section>


<section class="section">
  <div class="container is-max-desktop">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
          
          We present a novel method to learn Personalized Implicit Neural Avatars (PINA) from a short RGB-D sequence. This allows non-expert users to create a detailed and personalized virtual copy of themselves, which can be animated with realistic clothing deformations. PINA does not require complete scans, nor does it require a prior learned from large datasets  of  clothed  humans.   Learning  a  complete  avatar in this setting is challenging,  since only few depth observations are available, which are noisy and incomplete (i.e.only partial visibility of the body per frame). We propose a method to learn the shape and non-rigid deformations via a pose-conditioned implicit surface and a deformation field, defined in canonical space. This allows us to fuse all partial observations into a single consistent canonical representation. Fusion is formulated as a global optimization problem over the pose, shape and skinning parameters. The method can learn neural avatars from real noisy RGB-D sequences for  a  diverse  set  of  people  and  clothing  styles  and  these avatars can be animated given unseen motion sequences.
          
        </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
    


    <!-- Paper video. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
         <iframe width="560" height="315" src="https://www.youtube.com/embed/oGpKUuD54Qk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
        </div>
      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<section class="section" id="method">
  <div class="container is-max-desktop content">
    <h2 class="title">Method</h2>
    <img src="https://ait.ethz.ch/projects/2022/pina/downloads/assets/pipeline.png"  height="250" class="center"/>
    <p>
     TODO
    </p>

    
    <h3 class="title">Learning Shape and Skinning from "Crowdsampled" Posed Scans</h2>
    <p>
  
    </p>

    <h3 class="title">Learning 3D Wrinkles via 2D Adversarial Loss</h2>
    <p>
      
    </p>

  </div>
</section>

<section class="section" id="result">
  <div class="container is-max-desktop content">
    <h2 class="title">Result</h2>

    <h3 class="title">Disentangled Generation</h3>
    <p>
      Our model enables disentangled control over coarse shape, fine details, body pose and body size.
    </p>
    <div class="columns is-centered">
      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h4 class="title">Coarse Shape</h4>
          <video autoplay controls muted loop height="100%">
            <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/shape_crop.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h4 class="title">Fine Details</h4>
        <div class="columns is-centered">
          <div class="column content">
          <video autoplay controls muted loop height="100%">
            <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/detail_crop.mp4"
                    type="video/mp4">
          </video>
          </div>
        </div>
      </div>
    </div>

    <div class="columns is-centered">
      <!-- Visual Effects. -->
      <div class="column">
        <div class="content">
          <h4 class="title">Body Size</h4>
          <video autoplay controls muted loop height="100%">
            <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/size_crop.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div>
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <div class="column">
        <h4 class="title">Body Pose</h4>
        <div class="columns is-centered">
          <div class="column content">
          <video autoplay controls muted loop height="100%">
            <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/pose_crop.mp4"
                    type="video/mp4">
          </video>
          </div>
        </div>
      </div>
    </div>

    <h3 class="title">Interpolation+Animation</h3>
    <p>
      We interpolate between latent codes of training samples during animation.
    </p>
    <video poster="" id="chair-tp" autoplay controls muted loop width="50%">
      <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/interp_crop.mp4", type="video/mp4">
    </video>

    <h3 class="title">Random Sampling</h3>
    <p>
      We can randomly sample 3D avatars in various clothing and identities and animate them with pose sequences from existing motion databases.
    </p>

  <section class="hero is-light is-small">
    <div class="hero-body">
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item item-steve">
            <video poster="" autoplay controls muted loop height="100%">
              <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/sample1_crop.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" autoplay controls muted loop height="100%">
              <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/sample7_crop.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" autoplay controls muted loop height="100%">
              <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/sample2_crop.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" autoplay controls muted loop height="100%">
              <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/sample8_crop.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" autoplay controls muted loop height="100%">
              <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/sample3_crop.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" autoplay controls muted loop height="100%">
              <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/sample9_crop.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" autoplay controls muted loop height="100%">
              <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/sample4_crop.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" autoplay controls muted loop height="100%">
              <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/sample10_crop.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" autoplay controls muted loop height="100%">
              <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/sample5_crop.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" autoplay controls muted loop height="100%">
              <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/sample11_crop.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" autoplay controls muted loop height="100%">
              <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/sample6_crop.mp4" type="video/mp4">
            </video>
          </div>
          <div class="item item-chair-tp">
            <video poster="" autoplay controls muted loop height="100%">
              <source src="https://ait.ethz.ch/projects/2022/gdna/downloads/assets/sample12_crop.mp4" type="video/mp4">
            </video>
          </div>
        </div>
      </div>
    </div>
  </section>
  </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{chen2022gdna,
      title={gDNA: Towards Generative Detailed Neural Avatars},
      author={Chen, Xu and Jiang, Tianjian and Song, Jie and Yang, Jinlong and Black, Michael J and Geiger, Andreas and Hilliges, Otmar},    
      journal   = {arXiv},
      year      = {2022}
    }</code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="https://ait.ethz.ch/projects/2022/gdna/downloads/main.pdf">
        <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="https://github.com/keunhong" class="external-link" disabled>
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This webpage is built with the template from <a href="https://github.com/nerfies/nerfies.github.io">NeRFies</a>. We sincerely thank <a href="https://keunhong.com/">Keunhong Park</a> for developing and open-sourcing this template.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
